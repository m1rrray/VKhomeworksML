{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMxlcjLtLtof"
   },
   "source": [
    "### Машинное Обучения\n",
    "\n",
    "## Домашнее задание №2 - Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4EVGSTALtoi"
   },
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 23 апреля 2024, 23:59   \n",
    "**Штраф за опоздание:** -2 балла за каждые 2 дня опоздания\n",
    "\n",
    "Решений залить в свой github репозиторий.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB3jjegTLtoj"
   },
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zo6s0Y-VLtoj"
   },
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс MyDecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict . (Но название класса не менять)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.923375100Z",
     "start_time": "2024-04-23T14:02:32.567883400Z"
    },
    "id": "AnW-4Vs9Ltoj"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import entropy\n",
    "from sklearn import tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.928383400Z",
     "start_time": "2024-04-23T14:02:32.926383500Z"
    },
    "id": "_umE10eoLtok"
   },
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=5, criterion='gini'):\n",
    "        \"\"\"\n",
    "        criterion -- критерий расщепления. необходимо релизовать три:\n",
    "        Ошибка классификации, Индекс Джини, Энтропийный критерий\n",
    "        max_depth -- максимальная глубина дерева\n",
    "        min_samples_split -- минимальное число объектов в листе, чтобы сделать новый сплит\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "        self.criterion = criterion\n",
    "        self.tree = {}\n",
    "\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Разделяет объекты на 2 множества\n",
    "        x -- матрица объектов\n",
    "        y -- вектор ответов\n",
    "        feature_id -- айдишник признака, по которому делаем сплит\n",
    "        threshold -- порог, по которому делаем сплит\n",
    "        \"\"\"\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "\n",
    "    def get_impurity(self, feature, y):\n",
    "        \"\"\"\n",
    "        Функция вычисляет минимальное impurity для признака,\n",
    "        используется адаптированный для классификация\n",
    "        эффективный алгоритм из ноутбука с занятия\n",
    "        Принимает признак и целевые переменные\n",
    "        \"\"\"\n",
    "        best_impurity = float('inf')\n",
    "        best_thr = None\n",
    "\n",
    "        # сортировка значений признака и классов\n",
    "        idx = np.argsort(feature)\n",
    "        y_sorted, x_sorted = y[idx], feature[idx]\n",
    "\n",
    "        # всего объектов\n",
    "        total = len(y_sorted)\n",
    "        # количество объектов каждого класса\n",
    "        class_counts = np.bincount(y_sorted, minlength=np.max(y_sorted) + 1)\n",
    "        # количество классов\n",
    "        num_classes = len(class_counts)\n",
    "\n",
    "        # подготовка кумулятивных счетчиков для классов\n",
    "        # np.eye создает матрицу, где каждая строка соответствует one-hot кодировке класса для каждого объекта.\n",
    "        # кумулятивная сумма классов слева от каждого возможного разбиения (не включая последнее значение для избежания пустого разбиения)\n",
    "        left_counts = np.cumsum(np.eye(num_classes)[y_sorted], axis=0)[:-1]\n",
    "        # оставшиеся счетчики классов справа для каждого разбиения\n",
    "        right_counts = class_counts - left_counts\n",
    "\n",
    "        # размеры левой и правой части для каждого возможного разбиения\n",
    "        # индексы, которые будут использоваться как границы разбиения (от 1 до total-1).\n",
    "        sizes = np.arange(1, total)\n",
    "        # количество элементов слева и справа от каждого возможного разбиения\n",
    "        left_sizes = sizes\n",
    "        right_sizes = total - sizes\n",
    "\n",
    "\n",
    "        if self.criterion == 'gini':\n",
    "            left_impurity = 1 - np.sum((left_counts / left_sizes[:, None]) ** 2, axis=1)\n",
    "            right_impurity = 1 - np.sum((right_counts / right_sizes[:, None]) ** 2, axis=1)\n",
    "        elif self.criterion == 'entropy':\n",
    "            left_prob = left_counts / left_sizes[:, None]\n",
    "            right_prob = right_counts / right_sizes[:, None]\n",
    "            left_impurity = -np.sum(left_prob * np.log2(left_prob, where=left_prob > 0), axis=1)\n",
    "            right_impurity = -np.sum(right_prob * np.log2(right_prob, where=right_prob > 0), axis=1)\n",
    "        elif self.criterion == 'misclassification':\n",
    "            left_impurity = 1 - np.max(left_counts / left_sizes[:, None], axis=1)\n",
    "            right_impurity = 1 - np.max(right_counts / right_sizes[:, None], axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Wrong criterion\")\n",
    "\n",
    "        impurity = (left_impurity * sizes + right_impurity * right_sizes) / total\n",
    "\n",
    "        #  пропускает одинаковые значения признака\n",
    "        mask = np.append(True, x_sorted[1:] != x_sorted[:-1])\n",
    "\n",
    "        # применение маски для фильтрации impurity\n",
    "        filtered_impurity = np.where(mask[1:], impurity, float('inf'))\n",
    "\n",
    "        # нахождение минимального значения impurity\n",
    "        min_idx = np.argmin(filtered_impurity)\n",
    "        best_impurity = filtered_impurity[min_idx]\n",
    "        best_thr = (x_sorted[min_idx + 1] + x_sorted[min_idx]) / 2\n",
    "\n",
    "        return best_impurity, best_thr\n",
    "\n",
    "    def __find_threshold(self, X, y):\n",
    "        \"\"\"\n",
    "        функция, находящая лучший разделитель и\n",
    "        \"\"\"\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        best_impurity = float('inf')\n",
    "\n",
    "        for j in range(X.shape[1]):\n",
    "            impurity, threshold = self.get_impurity(X[:, j], y)\n",
    "            if impurity < best_impurity:\n",
    "                best_impurity = impurity\n",
    "                best_feature = j\n",
    "                best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth):\n",
    "        \"\"\"\n",
    "        Делаем новый узел в дереве\n",
    "        Решаем, терминальный он или нет\n",
    "        Если нет, то строим левый узел  с айди 2 * node_id + 1\n",
    "        И правый узел с  айди 2 * node_id + 2\n",
    "        \"\"\"\n",
    "        if depth == self.max_depth or x.shape[0] < self.min_samples_split or np.unique(y).size == 1:\n",
    "            # создаем лист, если мы достигли максимальной глубины, или количество объектов меньше,\n",
    "            # чем наш гиперпараметр, или все объекты в узле одного класса\n",
    "            class_counts = np.bincount(y, minlength=self.num_class)\n",
    "            predicted_class = np.argmax(class_counts)\n",
    "            self.tree[node_id] = (self.LEAF_TYPE, predicted_class, class_counts[predicted_class] / y.size)\n",
    "        else:\n",
    "\n",
    "            # выбор признака и порога для разделения\n",
    "            feature_id, threshold = self.__find_threshold(x, y)\n",
    "\n",
    "            if feature_id is None:\n",
    "                # Создание листа\n",
    "                class_counts = np.bincount(y, minlength=self.num_class)\n",
    "                predicted_class = np.argmax(class_counts)\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, predicted_class, class_counts[predicted_class] / y.size)\n",
    "                return\n",
    "\n",
    "            # разделение данных c помощью выбранного порога и признака\n",
    "            x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, threshold)\n",
    "            if x_left.size == 0 or x_right.size == 0:\n",
    "                # Если не удаётся разделить, делаем текущий узел листом\n",
    "                class_counts = np.bincount(y, minlength=self.num_class)\n",
    "                predicted_class = np.argmax(class_counts)\n",
    "                self.tree[node_id] = (self.LEAF_TYPE, predicted_class, class_counts[predicted_class] / y.size)\n",
    "                return\n",
    "\n",
    "            # добавляем новый узел, обновляем важность признаков, далее идем по рекурсии\n",
    "            self.tree[node_id] = (self.NON_LEAF_TYPE, feature_id, threshold)\n",
    "\n",
    "\n",
    "            # Вычисляем уменьшение критерия неопределенности для текущего разделения\n",
    "            impurity_decrease = self.calculate_impurity_decrease(x, y, feature_id, threshold)\n",
    "            self.feature_importances_[feature_id] += impurity_decrease\n",
    "\n",
    "            self.__fit_node(x_left, y_left, 2 * node_id + 1, depth + 1)\n",
    "            self.__fit_node(x_right, y_right, 2 * node_id + 2, depth + 1)\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        \"\"\"\n",
    "        Рекурсивно строим дерево решений\n",
    "        Начинаем с корня node_id 0\n",
    "        \"\"\"\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "\n",
    "        self.feature_importances_ = np.round(self.feature_importances_ /self.feature_importances_.sum(), 6)\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        \"\"\"\n",
    "        Рекурсивно обходим дерево по всем узлам,\n",
    "        пока не дойдем до терминального\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Вызывает predict для всех объектов из матрицы X\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)\n",
    "\n",
    "\n",
    "    def __predict_proba_node(self, x, node_id, positive_class):\n",
    "        \"\"\"\n",
    "        Предсказывает вероятность в узле\n",
    "        \"\"\"\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.LEAF_TYPE:\n",
    "            return np.array([1 - node[2], node[2]]) if node[1] == positive_class else np.array([node[2], 1 - node[2]])\n",
    "        _, feature_id, threshold = node\n",
    "        if x[feature_id] <= threshold:\n",
    "            return self.__predict_proba_node(x, 2 * node_id + 2, positive_class)\n",
    "        else:\n",
    "            return self.__predict_proba_node(x, 2 * node_id + 1, positive_class)\n",
    "\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Возвращает вероятности для каждого объекта, метод нужен для вероятнотностных метрик, типа roc auc\n",
    "        \"\"\"\n",
    "        return np.array([self.__predict_proba_node(x, 0, positive_class=1) for x in X])\n",
    "\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"\n",
    "        Выдает важность признаков\n",
    "        \"\"\"\n",
    "        if self.feature_importances_ is None:\n",
    "            raise ValueError(\"Модель еще не обучена\")\n",
    "\n",
    "        return self.feature_importances_\n",
    "\n",
    "\n",
    "    def calculate_impurity_decrease(self, x, y, feature_id, threshold):\n",
    "        \"\"\"\n",
    "        Вычисляет уменьшение критерия неопределенности при разделении по заданному признаку и порогу.\n",
    "        Используется для поиска самых информативных признаков\n",
    "        \"\"\"\n",
    "        x_left, x_right, y_left, y_right = self.__div_samples(x, y, feature_id, threshold)\n",
    "\n",
    "        node_impurity = self.calculate_node_impurity(y)\n",
    "\n",
    "        # можно было бы это притащить из get_impurity, но я не стал, поэтому и написал функцию calculate_node_impurity\n",
    "        left_impurity = self.calculate_node_impurity(y_left)\n",
    "        right_impurity = self.calculate_node_impurity(y_right)\n",
    "\n",
    "        # уменьшение нашего импурити\n",
    "        impurity_decrease = (node_impurity * x.shape[0] -\n",
    "                     left_impurity * x_left.shape[0] -\n",
    "                     right_impurity * x_right.shape[0])\n",
    "\n",
    "        return impurity_decrease\n",
    "\n",
    "    def calculate_node_impurity(self, y):\n",
    "        \"\"\"\n",
    "        Вычисляет критерий неопределенности для узла\n",
    "        \"\"\"\n",
    "        class_proba = np.bincount(y) / y.size\n",
    "\n",
    "        if self.criterion == 'gini':\n",
    "            impurity = 1 - np.sum(class_proba ** 2)\n",
    "        elif self.criterion == 'entropy':\n",
    "            impurity = -np.sum(class_proba * np.log2(class_proba, where = class_proba > 0))\n",
    "        elif self.criterion == 'misclassification':\n",
    "            impurity = 1 - np.max(class_proba)\n",
    "        else:\n",
    "            raise ValueError(\"Неверный критерий\")\n",
    "\n",
    "        return impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.927385200Z"
    },
    "id": "6NcLwo4PLtol"
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.932383400Z",
     "start_time": "2024-04-23T14:02:32.929381600Z"
    },
    "id": "z23z5J4pLtol"
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.931385Z"
    },
    "id": "bl3TXTtMg6VD"
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.937381500Z",
     "start_time": "2024-04-23T14:02:32.932383400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hi4zbVUKLtol",
    "outputId": "e9eaa499-53d6-438e-b886-c534897063c3"
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2b-69qXLtom"
   },
   "source": [
    "Совет: Проверьте, что ваша реализация корректно работает с признаками в которых встречаются повторы.\n",
    "И подумайте, какие еще граничные случаи могут быть.\n",
    "Например, проверьте, что на таком примере ваша модель корректно работает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.934381600Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGqvOFAXLtom",
    "outputId": "a257e467-c00e-4959-e0a8-a017f7ddc57b"
   },
   "outputs": [],
   "source": [
    "X = np.array([[1] * 10, [0, 1, 2, 5, 6, 3, 4, 7, 8, 9]]).T\n",
    "y = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
    "for depth in range(1, 5):\n",
    "    my_clf = MyDecisionTreeClassifier(max_depth=depth)\n",
    "    my_clf.fit(X, y)\n",
    "    print(accuracy_score(y, my_clf.predict(X)))\n",
    "    print(\"DEPTH:\", depth, \"\\n\\t\\tTree:\", my_clf.tree, my_clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EeNzNzCBLtom"
   },
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine.\n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.936384300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 111
    },
    "id": "UWXMy_E4Ltom",
    "outputId": "1c22237c-5497-4451-f716-b572b8c28d0e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.939379300Z",
     "start_time": "2024-04-23T14:02:32.938379300Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pUHDWKFSLton",
    "outputId": "105088df-426a-489b-8edf-fdfd5803e23c"
   },
   "outputs": [],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCEmlz94Lton"
   },
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match).\n",
    "\n",
    "Данные и описания колонок во вложениях.\n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Либо воспользоваться функцией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.941379200Z"
    },
    "id": "ulLXm1MkLton"
   },
   "outputs": [],
   "source": [
    "def preprocess_spd_data(df):\n",
    "    df = df.iloc[:, :97]\n",
    "\n",
    "    to_drop = [\n",
    "        'id', 'idg', 'condtn', 'round', 'position', 'positin1', 'order', 'partner',\n",
    "        'age_o', 'race_o', 'pf_o_att', 'pf_o_sin', 'pf_o_int', 'pf_o_fun', 'pf_o_amb', 'pf_o_sha',\n",
    "        'dec_o', 'attr_o', 'sinc_o', 'intel_o', 'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o','met_o',\n",
    "        'field', 'undergra', 'from', 'zipcode', 'income', 'career', 'sports', 'tvsports', 'exercise',\n",
    "        'dining', 'museums', 'art', 'hiking', 'gaming', 'clubbing', 'reading', 'tv', 'theater', 'movies',\n",
    "        'concerts', 'music', 'shopping', 'yoga', 'expnum',\n",
    "        'mn_sat', 'tuition'\n",
    "    ]\n",
    "\n",
    "    df = df.drop(to_drop, axis=1)\n",
    "    df = df.dropna(subset=['age', 'imprelig', 'imprace', 'date'])\n",
    "\n",
    "    df.loc[:, 'field_cd'] = df.loc[:, 'field_cd'].fillna(19)\n",
    "    df.loc[:, 'career_c'] = df.loc[:, 'career_c'].fillna(18)\n",
    "\n",
    "    # attr1 processing\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1',\n",
    "                                            'amb1_1', 'shar1_1']].sum(axis=1)\n",
    "    df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']] =\\\n",
    "    (df.loc[:, ['attr1_1', 'sinc1_1', 'intel1_1', 'fun1_1', 'amb1_1', 'shar1_1']].T /\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "\n",
    "    # attr2 processing\n",
    "    df.loc[:, 'temp_totalsum'] = df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1',\n",
    "                                            'amb2_1', 'shar2_1']].sum(axis=1)\n",
    "    df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']] =\\\n",
    "    (df.loc[:, ['attr2_1', 'sinc2_1', 'intel2_1', 'fun2_1', 'amb2_1', 'shar2_1']].T /\n",
    "     df.loc[:, 'temp_totalsum'].T).T * 100\n",
    "    df = df.drop(['temp_totalsum'], axis=1)\n",
    "\n",
    "    for i in [4, 5]:\n",
    "        feat = ['attr{}_1'.format(i), 'sinc{}_1'.format(i),\n",
    "                'intel{}_1'.format(i), 'fun{}_1'.format(i),\n",
    "                'amb{}_1'.format(i), 'shar{}_1'.format(i)]\n",
    "\n",
    "        if i != 4:\n",
    "            feat.remove('shar{}_1'.format(i))\n",
    "\n",
    "        df = df.drop(feat, axis=1)\n",
    "\n",
    "    df = df.drop(['wave'], axis=1)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uICCBCmiLton"
   },
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. В качестве метрики можно взять roc-auc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.944388Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IS9vyyduLton",
    "outputId": "0d876ca4-6e86-4863-cf00-a567ac7c929c"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Speed_Dating_Data.csv', encoding='latin1')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.946384900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "HXn477zkLton",
    "outputId": "b5e5ece9-b433-4bf8-dd63-cdd6096494e6"
   },
   "outputs": [],
   "source": [
    "preprocessed_df = preprocess_spd_data(df)\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.949385900Z"
    },
    "id": "s4VLosY2xWOu"
   },
   "outputs": [],
   "source": [
    "y = preprocessed_df.match.to_numpy()\n",
    "X = preprocessed_df.drop(\"match\", axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr2edT1u6Slf"
   },
   "source": [
    "У нас очень несбалансированы классы, поэтому имеет смысл применить SMOTE, это такой метод, который добавляет синтетичесике данные, чтобы выборка стала сбалансированной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.959893700Z",
     "start_time": "2024-04-23T14:02:32.953387400Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cP20PxSn6dxC",
    "outputId": "501663c0-0117-45f4-ba63-0c9a40f91acb"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X, y)\n",
    "\n",
    "print(X_resampled.shape, y_resampled.shape)\n",
    "\n",
    "np.unique(y_resampled, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPk2amSxLton"
   },
   "source": [
    "Разбейте датасет на трейн и валидацию. Подберите на валидации оптимальный критерий  информативности.\n",
    "Постройте графики зависимости точности на валидации и трейне от глубины дерева, от минимального числа объектов для сплита. (Т.е должно быть 2 графика, на каждой должны быть 2 кривые - для трейна и валидации)\n",
    "Какой максимальной точности удалось достигнуть?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.955389900Z"
    },
    "id": "IT80_Nbq65Nl"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.33, stratify=y_resampled, random_state=52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.958396100Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXawbqUo41Kg",
    "outputId": "66d8733f-b2bb-4dc3-c907-8e4efa13fbf3"
   },
   "outputs": [],
   "source": [
    "# Посмотрим какие ответы нам выдает решающее дерево из sklearn\n",
    "\n",
    "sk_tree = DecisionTreeClassifier(min_samples_split=10, max_depth=15,  criterion=\"gini\")\n",
    "sk_tree.fit(X_train, y_train)\n",
    "\n",
    "# Тут нам нужна proba, чтобы ro auc нормально работал, так как обычный предикт выдает просто 0 или 1\n",
    "pred_test_proba = sk_tree.predict_proba(X_test)[:, 1]\n",
    "pred_test = sk_tree.predict(X_test)\n",
    "\n",
    "pred_train_proba = sk_tree.predict_proba(X_train)[:, 1]\n",
    "pred_train = sk_tree.predict(X_train)\n",
    "\n",
    "# Смотрим метрики\n",
    "print(\"TEST\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_test)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, pred_test_proba)}\")\n",
    "\n",
    "print(\"TRAIN\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, pred_train)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_train, pred_train_proba)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU_NF2NUz0jc"
   },
   "source": [
    "Результаты довольно хорошие с такими гиперпараметры, я их взял из графиков ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:32.962902Z",
     "start_time": "2024-04-23T14:02:32.959893700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_44R6j2EDyI",
    "outputId": "0bd456c0-435f-4cee-d103-bba0bb03c01f"
   },
   "outputs": [],
   "source": [
    "# Обучаем наше деревео на такиж же гиперпараметрах как дерево из sklearn\n",
    "my_tree = MyDecisionTreeClassifier(min_samples_split=10, max_depth=15,  criterion=\"gini\")\n",
    "my_tree.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Тут также как выше\n",
    "pred_test_proba = my_tree.predict_proba(X_test)[:, 1]\n",
    "pred_test = my_tree.predict(X_test)\n",
    "\n",
    "pred_train_proba = my_tree.predict_proba(X_train)[:, 1]\n",
    "pred_train = my_tree.predict(X_train)\n",
    "\n",
    "# Смотрим метрики\n",
    "print(\"TEST\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, pred_test)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, pred_test_proba)}\")\n",
    "\n",
    "print(\"TRAIN\")\n",
    "print(f\"Accuracy: {accuracy_score(y_train, pred_train)}\")\n",
    "print(f\"ROC AUC: {roc_auc_score(y_train, pred_train_proba)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eJDr66tRpybZ"
   },
   "source": [
    "Наше дерево почти такое же как и дерево из sklearn, значит код написан верно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-23T14:02:33.040901500Z",
     "start_time": "2024-04-23T14:02:32.962902Z"
    },
    "id": "lxPV5zyV1plh"
   },
   "outputs": [],
   "source": [
    "def get_score_by_depth_or_split(\n",
    "    X_train, y_train, X_test, y_test,\n",
    "    DecisionTreeClassifier=DecisionTreeClassifier,\n",
    "    depth=10, samples_split=10,\n",
    "    score=accuracy_score,\n",
    "    kind=\"depth\"):\n",
    "  \"\"\"\n",
    "  Получаем два словаря зависимостей auc-roc или accuracy на трейне и тесте\n",
    "  от глубины дерева или от минимального числа объектов для сплита\n",
    "  \"\"\"\n",
    "\n",
    "  # словарики для ответов\n",
    "  res_test = {}\n",
    "  res_train = {}\n",
    "\n",
    "  # если идет проверка на глубину\n",
    "  if kind == \"depth\":\n",
    "    for i in range(1, depth):\n",
    "      # Инициализируем и обучаем дерево\n",
    "      tree = DecisionTreeClassifier(min_samples_split=samples_split, max_depth=i)\n",
    "      tree.fit(X_train, y_train)\n",
    "\n",
    "      # меняем метод в зависимости от метрики, которую мы используем\n",
    "      if score == accuracy_score:\n",
    "        pred_test = tree.predict(X_test)\n",
    "        pred_train = tree.predict(X_train)\n",
    "      else:\n",
    "        pred_test = tree.predict_proba(X_test)[:, 1]\n",
    "        pred_train = tree.predict_proba(X_train)[:, 1]\n",
    "\n",
    "      res_test[str(i)] = score(y_test, pred_test)\n",
    "      res_train[str(i)] = score(y_train, pred_train)\n",
    "\n",
    "  # если идет проверка на минимальное количество объектов в листе\n",
    "  elif kind == \"minsplit\":\n",
    "    for i in range(2, samples_split):\n",
    "      # Инициализируем и обучаем дерево\n",
    "      tree = DecisionTreeClassifier(min_samples_split=i, max_depth=depth)\n",
    "      tree.fit(X_train, y_train)\n",
    "\n",
    "      # меняем метод в зависимости от метрики, которую мы используем\n",
    "      if score == accuracy_score:\n",
    "        pred_test = tree.predict(X_test)\n",
    "        pred_train = tree.predict(X_train)\n",
    "      else:\n",
    "        pred_test = tree.predict_proba(X_test)[:, 1]\n",
    "        pred_train = tree.predict_proba(X_train)[:, 1]\n",
    "\n",
    "      res_test[str(i)] = score(y_test, pred_test)\n",
    "      res_train[str(i)] = score(y_train, pred_train)\n",
    "\n",
    "  return res_train, res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.964907300Z"
    },
    "id": "ZeqTmtCLxVrq"
   },
   "outputs": [],
   "source": [
    "def plot_auc_roc_by_depth(train_values, test_values, score=accuracy_score, kind=\"depth\"):\n",
    "  \"\"\"\n",
    "  Рисуем график зависимости auc-roc от глубины дерева на трейне и тесте\n",
    "  \"\"\"\n",
    "  plt.figure(figsize=(13, 6))\n",
    "  plt.plot(range(1, len(test_values) + 1), test_values, label=\"Test\")\n",
    "  plt.plot(range(1,len(train_values) + 1), train_values, label=\"Train\")\n",
    "\n",
    "  plt.title(f\"Значение {score.__name__} в зависимости от {kind}\")\n",
    "  plt.xlim((1, len(test_values) + 1))\n",
    "  plt.legend()\n",
    "  plt.xlabel(f\"{kind}\")\n",
    "  plt.ylabel(score.__name__)\n",
    "  plt.grid()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.966902300Z"
    },
    "id": "GiENbEG836_j"
   },
   "outputs": [],
   "source": [
    "# Получаем значения accuracy для минимального количества объектов от 2 до 49, глубина 15\n",
    "\n",
    "res_by_depth_train, res_by_depth_test = get_score_by_depth_or_split(X_train, y_train, X_test, y_test,\n",
    "                                                                        DecisionTreeClassifier=MyDecisionTreeClassifier,\n",
    "                                                                        depth=15, kind='minsplit',\n",
    "                                                                        score=accuracy_score,\n",
    "                                                                        samples_split=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQmpqkGvoVvH"
   },
   "source": [
    "Теперь построим график для визуальной оценки зависимости accuracy от минимального количества объектов в листе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.967900800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "O6hCIfQSzyvb",
    "outputId": "d4b702b7-b57b-409c-d303-a8cc9a7f6d21"
   },
   "outputs": [],
   "source": [
    "plot_auc_roc_by_depth(res_by_depth_train.values(), res_by_depth_test.values(), kind='minsplit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.969908300Z"
    },
    "id": "AudMBubO5PRZ",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Получаем значения accuracy для глубины дерева от 1 до 25, минимальное колмчество объектов в листе 10\n",
    "\n",
    "res_by_depth_train_2, res_by_depth_test_2 = get_score_by_depth_or_split(X_train, y_train, X_test, y_test,\n",
    "                                                                        DecisionTreeClassifier=MyDecisionTreeClassifier,\n",
    "                                                                        depth=25, kind='depth',\n",
    "                                                                        score=accuracy_score,\n",
    "                                                                        samples_split=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTcS9YitzUDh"
   },
   "source": [
    "Теперь построим график для визуальной оценки зависимости accuracy от глубины в дереве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.970904Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "57amwCIZ5UJr",
    "is_executing": true,
    "outputId": "307ac250-a8ee-4dd8-8be8-3c0688b94988"
   },
   "outputs": [],
   "source": [
    "plot_auc_roc_by_depth(res_by_depth_train_2.values(), res_by_depth_test_2.values(), kind='depth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9KmmBd11F0x"
   },
   "source": [
    "Получилось достичь довольно хорошего качества. На тесте accuracy 0.80, а roc auc 0.86, это при глубине 15 и min_sample_split 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsNB-B7BLtoo"
   },
   "source": [
    "Известным фактом является то, что деревья решений сильно переобучаются при увеличении глубины и просто запоминают трейн.\n",
    "Замечаете ли вы такой эффект судя по графикам? Что при этом происходит с качеством на валидации?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpEGoX3j10mx"
   },
   "source": [
    "ОТВЕТ: Да, видно на графиках, что деревья переобучаются при большой глубине или маленьком min_sample_split. Чем меньше min_sample_split, тем выше трейн, тест не сильно меняется, но все равно есть небольшие скачки. На сильно больших min_sample_split начинает просаживаться и тест. Чем больше глубина, тем выше трейн, что говорит о переобучении. Тест выходит на плато и сильно не меняется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyS02XTALtoo"
   },
   "source": [
    "## Находим самые важные признаки (2 балла)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQIQFYhBLtoo"
   },
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lai59gxcLtoo"
   },
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший.\n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tXhVUnCYLtoo"
   },
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nzKyVibTLtoo"
   },
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.971905100Z"
    },
    "id": "WGerLp1w-_xh",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "def show_best_features(features):\n",
    "    \"\"\"\n",
    "    Выводит 10 самых важных признаков\n",
    "    \"\"\"\n",
    "    new_pd = pd.DataFrame(\n",
    "    {\"feature\": preprocessed_df.drop('match', axis=1).columns, \"importance\": list(features)}\n",
    "    )\n",
    "    return new_pd.sort_values(by=\"importance\", ascending=False).reset_index(drop=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.972902700Z"
    },
    "id": "C71gzdpVLtoo",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "final_my_tree = MyDecisionTreeClassifier(min_samples_split=10, max_depth=15, criterion=\"gini\")\n",
    "final_my_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.974903800Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sscQP3-4Ltoo",
    "is_executing": true,
    "outputId": "3f50c65f-6ac4-4106-a4ba-b41a7b8cefd6"
   },
   "outputs": [],
   "source": [
    "my_features = final_my_tree.get_feature_importance()\n",
    "my_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.975903700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "3EaZ65_sAQ4-",
    "is_executing": true,
    "outputId": "2e2ddf3e-19b2-42d1-b077-36c97803c9ec"
   },
   "outputs": [],
   "source": [
    "show_best_features(my_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmltsaX5C2tZ"
   },
   "source": [
    "Теперь сравним наши результаты с аналогичным методом из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.977907Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "K4YoCVuEH_pj",
    "is_executing": true,
    "outputId": "024dc866-7f26-432b-f176-78f5c226827d"
   },
   "outputs": [],
   "source": [
    "final_sk_tree = DecisionTreeClassifier(min_samples_split=10, max_depth=15, criterion=\"gini\")\n",
    "final_sk_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.979908200Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sV9UWZE-IJ6D",
    "is_executing": true,
    "outputId": "0c8e94d4-8929-4442-e23e-ccbffdc235ab"
   },
   "outputs": [],
   "source": [
    "sk_features = final_sk_tree.feature_importances_\n",
    "sk_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.980900700Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "DIDrQtKEngBB",
    "is_executing": true,
    "outputId": "4093d805-3ce9-4dcb-a6dc-30a7354d2340"
   },
   "outputs": [],
   "source": [
    "show_best_features(sk_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FsTzeRpTEwdV"
   },
   "source": [
    "Мои самые важные признаки совпадают с самыми важными признаками из sklearn, значит код работает верно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIp72Nc0Ltoo"
   },
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT7cShSgLtop"
   },
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7QIkal0Ltop"
   },
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4O1Qbz4ODGrC"
   },
   "source": [
    "Довольно сложно было писать само дерево, очень сложно было реализовывать метод __get_impurity, чтобы он быстро работал. Также довольно много времени потратил на feature_importance, чтобы получить аналогичные результаты как в sklearn. В принципе, нормально, за пару дней делается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDxZ2kCqLtoq"
   },
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.982904Z"
    },
    "collapsed": true,
    "id": "w_drLemeLtoq",
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-23T14:02:32.983904200Z"
    },
    "collapsed": true,
    "id": "KsXtZOokLtoq",
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
